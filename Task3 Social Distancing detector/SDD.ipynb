{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff990ab",
   "metadata": {},
   "source": [
    "# Task_3: Social_Distancing_detector\n",
    "\n",
    "Social distancing is a method used to control the spread of contagious diseases. It implies that people physically distance themselves from one another, reducing close contact, and thereby reducing the spread of a contagious disease (such as the COVID-19 Disease).\n",
    "\n",
    "In this tutorial, I will implement a COVID-19 social distancing detector using yolov3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12086f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import config\n",
    "from detection import detect_people\n",
    "from scipy.spatial import distance as dist \n",
    "import numpy as np\n",
    "import argparse\n",
    "from numba import cuda\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4352f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--video-path\", type=str, default=\"video.mp4\", help=\"path to (optional) input video file\")\n",
    "ap.add_argument(\"-o\", \"--video-output-path\", type=str, default=\"output.avi\", help=\"path to (optional) output video file\")\n",
    "ap.add_argument(\"-d\", \"--display\", type=int, default=1, help=\"whether or not output frame should be displayed\")\n",
    "args, unknown = ap.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277bf8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load class labels\n",
    "LABELS = \"./coco.names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745436ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = \"./yolov3.cfg\"\n",
    "weights = \"./yolov3.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33579cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n"
     ]
    }
   ],
   "source": [
    "# load YOLO object detector\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(cg, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df442ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] setting preferable backend and target to CUDA...\n"
     ]
    }
   ],
   "source": [
    "# set CUDA s the preferable backend and target\n",
    "print(\"[INFO] setting preferable backend and target to CUDA...\")\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4756ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine only the \"output\" layer names that we need from YOLO\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf63c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "if args.video_path:\n",
    "# initialize the video stream and pointer to output video file\n",
    "    print(\"[INFO] accessing video stream...\")\n",
    "# open input video if available else webcam stream\n",
    "    vs = cv2.VideoCapture(args.video_path if args.video_path else 0)\n",
    "    writer = None\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        # read the next frame from the input video\n",
    "        (grabbed, frame) = vs.read()\n",
    "\n",
    "        # if the frame was not grabbed, then that's the end fo the stream \n",
    "        if not grabbed:\n",
    "            break\n",
    "\n",
    "        # resize the frame and then detect people (only people) in it\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "        results = detect_people(frame, net, ln)\n",
    "\n",
    "        # initialize the set of indexes that violate the minimum social distance\n",
    "        violate = set()\n",
    "\n",
    "        # ensure there are at least two people detections (required in order to compute the\n",
    "        # the pairwise distance maps)\n",
    "        if len(results) >= 2:\n",
    "            # extract all centroids from the results and compute the Euclidean distances\n",
    "            # between all pairs of the centroids\n",
    "            centroids = np.array([r[2] for r in results])\n",
    "            D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "            # loop over the upper triangular of the distance matrix\n",
    "            for i in range(0, D.shape[0]):\n",
    "                for j in range(i+1, D.shape[1]):\n",
    "                    # check to see if the distance between any two centroid pairs is less\n",
    "                    # than the configured number of pixels\n",
    "                    if D[i, j] < config.MIN_DISTANCE:\n",
    "                        # update the violation set with the indexes of the centroid pairs\n",
    "                        violate.add(i)\n",
    "                        violate.add(j)\n",
    "\n",
    "        # loop over the results\n",
    "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "            # extract teh bounding box and centroid coordinates, then initialize the color of the annotation\n",
    "            (startX, startY, endX, endY) = bbox\n",
    "            (cX, cY) = centroid\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            # if the index pair exists within the violation set, then update the color\n",
    "            if i in violate:\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            # draw (1) a bounding box around the person and (2) the centroid coordinates of the person\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "            cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "        # draw the total number of social distancing violations on the output frame\n",
    "        text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "        cv2.putText(frame, text, (10, frame.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "\n",
    "        # check to see if the output frame should be displayed to the screen\n",
    "        if args.display > 0:\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Output\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the 'q' key is pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # if  the video writer has not been  as none\n",
    "        if writer is None:\n",
    "            # initialize the video writer\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(args.video_output_path, fourcc, 25, (frame.shape[1], frame.shape[0]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee55d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
